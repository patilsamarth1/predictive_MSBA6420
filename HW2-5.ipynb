{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, cohen_kappa_score, classification_report, make_scorer \n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB, CategoricalNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the data. Encoding the input and output variables with inputs as categoral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['acc', 'good', 'unacc', 'vgood'], dtype=object)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/car.data', header=None)\n",
    "X, Y = data.iloc[:, :-1], data.iloc[:, -1]\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "X = OneHotEncoder(sparse=False).fit_transform(X)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state = 29, stratify = Y)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3]), array([ 384,   69, 1210,   65], dtype=int64))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the classifiers and gridSearch for inner loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa_scorer = make_scorer(cohen_kappa_score)   \n",
    "\n",
    "complexity_values = range(1,10)\n",
    "\n",
    "clf1 = DecisionTreeClassifier(class_weight='balanced')\n",
    "p_grid1 = [{'max_depth': complexity_values, 'criterion': ['gini', 'entropy']}]\n",
    "\n",
    "clf2 = KNeighborsClassifier(metric='hamming')\n",
    "p_grid2 = [{'n_neighbors': complexity_values}]\n",
    "\n",
    "clf3 = LogisticRegression(class_weight='balanced', max_iter=10000)\n",
    "p_grid3 = [{'C': np.power(10, range(0,10))}]\n",
    "\n",
    "clf4 = SVC(class_weight='balanced')\n",
    "p_grid4 = [{'kernel': ['rbf'], 'C': np.power(10, range(0,5)), 'gamma': np.power(10., range(-5,0))},\n",
    "        {'kernel': ['linear'], 'C': np.power(10, range(0,5))}]\n",
    "\n",
    "clf5 = CategoricalNB()\n",
    "p_grid5 = [{'fit_prior': [True, False], 'alpha': np.arange(0.1,1,0.3)}]\n",
    "\n",
    "\n",
    "inner_cv = StratifiedKFold(n_splits=4, shuffle=True)\n",
    "outer_cv = StratifiedKFold(n_splits=4, shuffle=True)\n",
    "grid_cv = []\n",
    "\n",
    "# Kappa is chosen for scoring because of imbalanced multi-class dataset\n",
    "for p_grid, est in zip((p_grid1, p_grid2, p_grid3, p_grid4, p_grid5), (clf1, clf2, clf3, clf4, clf5)):\n",
    "    gs = GridSearchCV(estimator=est, param_grid=p_grid, scoring=kappa_scorer, cv=inner_cv)\n",
    "    grid_cv.append(gs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the nested-cv and getting the mean and standard deviation of the scores for each of the 5 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.873271781364809, 0.015165179326646407),\n",
       " (0.7937089846948181, 0.04676177058390272),\n",
       " (0.8492872127399249, 0.02047771197204182),\n",
       " (0.9904841147813505, 0.009516000647598992),\n",
       " (0.7253691310266324, 0.031789407271968516)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_scores = []\n",
    "for gs in grid_cv:\n",
    "    nested_score = cross_val_score(gs, X=x_train, y=y_train, cv=outer_cv, scoring=kappa_scorer)\n",
    "    nested_scores.append((nested_score.mean(), nested_score.std()))\n",
    "\n",
    "nested_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the nested-cv, the best model seems to be the 4th one - SVC<br>\n",
    "Find the best hyper-parameters for the SVC model and retrain on the whole train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=4, random_state=None, shuffle=True),\n",
       "             estimator=SVC(class_weight='balanced'),\n",
       "             param_grid=[{'C': array([    1,    10,   100,  1000, 10000], dtype=int32),\n",
       "                          'gamma': array([1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01]),\n",
       "                          'kernel': ['rbf']},\n",
       "                         {'C': array([    1,    10,   100,  1000, 10000], dtype=int32),\n",
       "                          'kernel': ['linear']}],\n",
       "             scoring=make_scorer(cohen_kappa_score))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_model = GridSearchCV(estimator=clf4, param_grid=p_grid4, scoring=kappa_scorer, cv=inner_cv)\n",
    "hp_model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 77   0   0   0]\n",
      " [  0  14   0   0]\n",
      " [  0   0 242   0]\n",
      " [  1   0   0  12]]\n",
      "0.9936854400116801\n",
      "0.9971098265895953\n"
     ]
    }
   ],
   "source": [
    "best_model = hp_model.best_estimator_\n",
    "pred = best_model.predict(pd.DataFrame(x_test))\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(cohen_kappa_score(y_test, pred))\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.99      1.00      0.99        77\n",
      "        good       1.00      1.00      1.00        14\n",
      "       unacc       1.00      1.00      1.00       242\n",
      "       vgood       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           1.00       346\n",
      "   macro avg       1.00      0.98      0.99       346\n",
      "weighted avg       1.00      1.00      1.00       346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred, target_names = ['acc', 'good', 'unacc', 'vgood']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the f1-scores for all classes, the model is performing<br>\n",
    "the worst on 'vgood' class with a score of 0.96. But the difference is not huge. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Th input variables fit better as categorical becuase the difference <br>\n",
    "in values is not the same at different values.  <br>\n",
    "Treating inputs as numeric preserves the order but also <br>\n",
    " missplaces importance on values with large differences. <br> \n",
    "But we can test if treating them as numeric is better. <br>\n",
    "Treating the inputs as numeric variables and repeating the process as above - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = data.iloc[:, :-1], data.iloc[:, -1]\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "X[0].replace({'vhigh':4, 'high':3, 'med':2, 'low':1}, inplace=True)\n",
    "X[1].replace({'vhigh':4, 'high':3, 'med':2, 'low':1}, inplace=True)\n",
    "X[2].replace({'5more':5,'5':4,'4':3, '3':2, '2':1}, inplace=True)\n",
    "X[3].replace({'more':3, '4':2, '2':1}, inplace=True)\n",
    "X[4].replace({'big':3, 'med':2, 'small':1}, inplace=True)\n",
    "X[5].replace({'high':3, 'med':2, 'low':1}, inplace=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state = 29, stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa_scorer = make_scorer(cohen_kappa_score)   \n",
    "\n",
    "complexity_values = range(1,10)\n",
    "\n",
    "clf1 = DecisionTreeClassifier(class_weight='balanced')\n",
    "p_grid1 = [{'max_depth': complexity_values, 'criterion': ['gini', 'entropy']}]\n",
    "\n",
    "clf2 = KNeighborsClassifier()\n",
    "p_grid2 = [{'n_neighbors': complexity_values}]\n",
    "\n",
    "clf3 = LogisticRegression(class_weight='balanced', max_iter=10000)\n",
    "p_grid3 = [{'C': np.power(10, range(0,10))}]\n",
    "\n",
    "clf4 = SVC(class_weight='balanced')\n",
    "p_grid4 = [{'kernel': ['rbf'], 'C': np.power(10, range(0,5)), 'gamma': np.power(10., range(-5,0))},\n",
    "        {'kernel': ['linear'], 'C': np.power(10, range(0,5))}]\n",
    "\n",
    "clf5 = CategoricalNB()\n",
    "p_grid5 = [{'fit_prior': [True, False], 'alpha': np.arange(0.1,1,0.3)}]\n",
    "\n",
    "\n",
    "inner_cv = StratifiedKFold(n_splits=4, shuffle=True)\n",
    "outer_cv = StratifiedKFold(n_splits=4, shuffle=True)\n",
    "grid_cv = []\n",
    "\n",
    "# Kappa is chosen for scoring because of imbalanced multi-class dataset\n",
    "for p_grid, est in zip((p_grid1, p_grid2, p_grid3, p_grid4, p_grid5), (clf1, clf2, clf3, clf4, clf5)):\n",
    "    gs = GridSearchCV(estimator=est, param_grid=p_grid, scoring=kappa_scorer, cv=inner_cv)\n",
    "    grid_cv.append(gs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9368419987387435, 0.012443109671196034),\n",
       " (0.811974157651929, 0.027782632356014948),\n",
       " (0.583570805323317, 0.02959426397700011),\n",
       " (0.9638221039403134, 0.0024986763767707435),\n",
       " (0.6268096426122767, 0.014399231709740709)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_scores = []\n",
    "for gs in grid_cv:\n",
    "    nested_score = cross_val_score(gs, X=x_train, y=y_train, cv=outer_cv, scoring=kappa_scorer)\n",
    "    nested_scores.append((nested_score.mean(), nested_score.std()))\n",
    "\n",
    "nested_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=4, random_state=None, shuffle=True),\n",
       "             estimator=SVC(class_weight='balanced'),\n",
       "             param_grid=[{'C': array([    1,    10,   100,  1000, 10000], dtype=int32),\n",
       "                          'gamma': array([1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01]),\n",
       "                          'kernel': ['rbf']},\n",
       "                         {'C': array([    1,    10,   100,  1000, 10000], dtype=int32),\n",
       "                          'kernel': ['linear']}],\n",
       "             scoring=make_scorer(cohen_kappa_score))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_model = GridSearchCV(estimator=clf4, param_grid=p_grid4, scoring=kappa_scorer, cv=inner_cv)\n",
    "hp_model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 75   0   2   0]\n",
      " [  0  14   0   0]\n",
      " [  8   0 234   0]\n",
      " [  2   0   0  11]]\n",
      "0.9254845656855707\n",
      "0.9653179190751445\n"
     ]
    }
   ],
   "source": [
    "best_model = hp_model.best_estimator_\n",
    "pred = best_model.predict(pd.DataFrame(x_test))\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(cohen_kappa_score(y_test, pred))\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, treating the inputs as categorical values gives better model performance."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98dd8f7ab5e670de6f15440e4dbf104f6a22fa9efc0b623d651b0cd672a901b5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
